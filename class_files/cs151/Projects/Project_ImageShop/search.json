[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "introduction/usage.html",
    "href": "introduction/usage.html",
    "title": "Understanding the Initial Program",
    "section": "",
    "text": "This repository contains a skeleton version of ImageShop.py, which is the main module that you will need to modify (although you will have to create one other). There are a few other useful library files you will need for this project as well included, so take the time to browse over what resources are available to you. Running the ImageShop.py code in the repository will initially create the screen image shown in Figure 1 (a), which includes a button area to the left of the screen with Load and Flip Vertical buttons and then a blank area to the right where the image will be displayed.\nClicking Load brings up a file chooser that lets you select an image. A directory of sample images has been included in the repository, so if you navigate to the images folder you will see a list of the image files included in this project. If you select VanGogh-StarryNight.png, ImageShop will load that file and center it in the image area, as shown in Figure 1 (b). If you then click the Flip Vertical button, you will get the picture shown in Figure 1 (c), with the inverted image. Clicking the Flip Vertical button again restores the original image.\n\n\n\n\n\n\n\n\n\n\n\n(a) Initial screen upon running ImageShop.py. An area to the left will hold all the buttons and the images will appear to the right.\n\n\n\n\n\n\n\n\n\n\n\n(b) Initially loading the VanGogh image and having it appear centered on the screen\n\n\n\n\n\n\n\n\n\n\n\n(c) The VanGogh image after pressing the Flip Vertically button.\n\n\n\n\n\n\n\nFigure 1: Running the program and then loading and manipulating the VanGogh-StarryNight.png image in the supplied images folder in the repository.",
    "crumbs": [
      "Understanding the Initial Program"
    ]
  },
  {
    "objectID": "milestones/milestone3.html",
    "href": "milestones/milestone3.html",
    "title": "Milestone 3: The Green Screen button",
    "section": "",
    "text": "The Green Screen button implements an operation that is used all the time in movies to merge actors into a background scene. The basic technique is called chroma keying, in which a particular range of colors is used to represent a background that can later be made transparent using a computational process. The most common colors used in chroma keying are green and blue (which give rise to the more specific names green screen and blue screen) because those colors are most easily differentiated from flesh tones.\nWhen the studios use the green screen technique, for example, the actors are filmed in front of a green background. The digital images are then processed so that green pixels are made transparent, so that the background shows through when the partially transparent image is overlaid on top of the background image.\nTo illustrate this process, suppose that you are making Star Wars: The Force Awakens and that you want to superimpose an image of Daisy Ridley’s character Rey on top of a shot of the interior of the Millennium Falcon shown in Figure 1 (a). You then shoot an image of Rey in front of a green screen like that shown in Figure 1 (b).\n\n\n\n\n\n\n\n\n\n\n\n(a) Background shot of the interior of the Millennium Falcon\n\n\n\n\n\n\n\n\n\n\n\n(b) Shot of Rey in front of a green screen.\n\n\n\n\n\n\n\nFigure 1: The two necessary component images for a composite green screen image.\n\n\n\nIf you skip the green pixels in Figure 1 (b) and copy all the others on top of Figure 1 (a), you get the composite image shown in Figure 2.\n\n\n\n\n\n\nFigure 2: Composite image of Rey inside the Millennium Falcon. Note that this is not two GImages stacked on top of one another, but a single image where non-green pixels have been copied from one image into the other.\n\n\n\nThe user should always first load the desired background image as per usual using Load. Then, when the user clicks the Green Screen button, the first thing your program has to do is read in a new image using the choose_input_file function in the filechooser module in much the same way as the load_action function does in the supplied starter code. Once you have the new GImage, you need to go through each pixel in both the old image and the new image and replace the old pixel value with the new one, unless the new pixel is green (at least by some definition).\nIt is unlikely though that the pixels that appear in the portion of the green screen image will have a color value exactly equal to the color \"Green\". Instead, they will have pixel values that lie in a range of colors that appear to be “mostly green”. For this part of the assignment, you should treat a pixel as green if its green component is at least twice as large as the largest of its red and blue components.\nIt is not necessary for the old image and the new image to have the same size. Your program should assume that the upper left corners of the two images are at the same place, and update only those pixels whose coordinates exist in both images. The final image, however, should be the same size as the original, and not the overlay. If the images are the same size, as they are for the Millenniumfalcon.png and ReyGreenScreen.png in the images folder, then the overlay operation will include every pixel in the image. Make sure you test overlaying Rey atop other images to ensure that your function behaves properly for differently sized images!\n\n\n\n\n\n\nWarning\n\n\n\nThe most common reason students lose points on this milestone is by not ensuring that their code works with all sorts of image sizes. Test your code! Overlay Rey atop every single other image in the image folder. You should never get any index out-of-bounds errors!",
    "crumbs": [
      "Milestone 3: The Green Screen button"
    ]
  },
  {
    "objectID": "milestones/milestone4.html",
    "href": "milestones/milestone4.html",
    "title": "Milestone 4: The Equalize button",
    "section": "",
    "text": "Digital processing can do an amazing job of enhancing a photograph. Consider, for example, the countryside image on the left in Figure 1. Particularly when you compare it to the enhanced version on the right, the picture on the left seems hazy. The enhanced version is the result of applying an algorithm called histogram equalization, which spreads out the intensities shown in the picture to increase its effective contrast and make it easier to identify individual features.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Before and after images illustrating the histogram equalization algorithm results. Left image from Wikipedia.\n\n\n\nAs described in Section 8.7 of the PDF reader (and in class), the individual pixels in an image are represented using four single-byte values, one for the transparency of the image and three representing the intensity of the red, green, and blue components of the color. The human eye perceives some colors as brighter than others, much in the same way that it perceives audible tones of certain frequencies as louder than others. The color green, for example, appears brighter than either red or blue, and if our eyes were more sensitive to violet hues, the sky would appear more purple instead of the blue we currently see.\n\nUnderstanding Luminance\nThis concept of brightness can be quantified using the idea of luminance, as described on page 262 in the PDF reader. That idea is implemented as a luminance function, which is defined in the GrayscaleImage module in the repository. The value returned by luminance is an integer between 0 and 255, just like the intensity values for red, green, and blue. A luminance of 0 indicates black, a luminance of 255 indicates white, and any other color falls somewhere in between.\nThe histogram-equalization algorithm you need to write for this assignment uses luminosities rather than colors and therefore produces a grayscale image, much as you did when you implemented the Grayscale button.\nThe entire histogram-equalization process requires several steps, each of which is best coded as a helper function. Because all of these functions will be related to the same idea, it is recommended to write them all in their own file, perhaps called equalization.py, and then import what you need into ImageShop.py. The various pieces (and functions) that you’ll want to write are described in the follow sub-milestones.\n\n\nCalculating the image histogram\nGiven an image, there may be multiple pixels that all have the same luminance. In fact, there almost certainly are! After all, there are only 256 possible luminance values, and most images will have thousands of individual pixels. An image histogram is a representation of the distribution of the luminance throughout the image. Specifically, the histogram is an array of 256 integers–one for each possible luminance–where each entry in the array represents the number of pixels in the image with that luminance. For example, the entry at index 0 of the array represents the number of pixels in the image with a luminance of 0 (or pure black). The entry an index 1 represents the number of pixels in the image with luminance of 1 (pure white), and so on and so forth. Your task in this sub-milestone is to write a function to generate an image histogram of the luminosities of a provided image or pixel array.\nLooking at an image’s histogram tells you a lot about the distribution of brightness throughout the image. The images at the top of Figure 2, for example, shows the original low-contrast picture of the countryside, along with its image histogram. The bottom row shows an image and histogram for a high-contrast image. Images with low contrast tend to have histograms more tightly clustered around a small number of values, while images with higher contrasts tend to have histograms that are more spread out over the full possible range of values.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Comparison of histograms for a low contrast image (top) and a high contrast image (bottom). Higher contrast images result in a much broader spread of the image luminosities in the histogram. Bottom left image from Ansel Adams Gallery.\n\n\n\nThe point of making this an intermediate sub-milestone is to emphasize that you need to test it, even if it isn’t easy to see the result. The histogram array will have 256 elements. You can either print the histogram on the console or use the graphical histogram functions from the most recent problem set to check whether your distribution matches the above graphs.\n\n\nCalculating the cumulative histogram\nRelated to the image histogram is the cumulative histogram, which shows not simply how many pixels have a particular luminance, but rather how many pixels have a particular luminance or lower. Like the image histogram, the cumulative histogram is an array of 256 values: one for each possible value of the luminance. You can compute the cumulative histogram purely from the image histogram. Each entry in the cumulative histogram is the sum of all the entries in the image histogram up to and including that index position. As an example, if the first six entries in the image histogram are:\n[1, 3, 5, 7, 9, 11]\nthen the corresponding entries in the cumulative histogram are calculated as:\n[1, 1+3, 1+3+5, 1+3+5+7, 1+3+5+7+9, 1+3+5+7+9+11]\nor, in other words:\n[1, 4, 9, 16, 25, 36]\nIn Figure 3 we can see the cumulative histograms for the two images from Figure 2. Notice how the low-contrast image has a sharp transition in its cumulative histogram, while the higher-contrast image tends to have a smoother increase over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Comparison of cumulative histograms for a low contrast image (top) and a high contrast image (bottom). Lower contrast images tend to create a much sharper “wall” in the cumulative histogram, versus the more gradual increase in higher contrast images.\n\n\n\nAfter creating these cumulative histograms, you could still test them using the same visualization tools you used for the normal histograms! Make sure things are looking correct before continuing!\n\n\nThe histogram-equalization algorithm\nThe cumulative histogram provides just what you need for the histogram-equalization algorithm. To get a sense to how it works, it helps to start with an example. Suppose that you have a pixel in the original image whose luminance is 106. Since the maximum possible luminance for a pixel is 255, this means that the “relative” luminance of this pixel is 106 / 255 \\approx 41.5 percent, which means that the pixel’s luminance is roughly 41.5 percent of the maximum possible. If you were to assume that all the intensities were distributed evenly across the image, you would expect this particular pixel to have a brightness greater than 41.5 percent of the other pixels in the image.\nSimilarly, suppose you have another pixel in the original image whose luminance is 222. The relative luminance of this pixel is 222/255 \\approx 87.1 percent, so we would expect that, should the intensities be evenly distributed, this pixel would be brighter than 87.1 percent of the pixels in the image.\nThe histogram equalization algorithm works by trying to change the intensities of the pixels in the original image as follows: if a pixel is supposed to be brighter than X percent of the pixels in the image, then the algorithm attempts to map it to a luminance that will make it brighter than as close to X percent of the total pixels as possible. In doing so, the algorithm attempts to more evenly distribute the luminosities across the total available options. Implementing this process turns out to be much easier than it might seem, especially if you have the cumulative histogram for an image.\nThe key idea is as follows. Suppose that an original pixel in the image has luminance L. If you look up the L^{th} entry in the cumulative histogram for the image, you will get back the total number of pixels in the image that have luminance of L or less (that is literally what the cumulative histogram tells you). You could then convert this value into the fraction of pixels in the image with luminance L or less by dividing by the total number of pixels in the image. Once you have the fraction of pixels with intensities less than or equal to the current luminance L, you can scale this number (which is currently between 0 and 1) so that it is between 0 and 255, which produces a valid luminance. The histogram equalization therefore consists of the following steps:\n\nCompute the image histogram from the original image\nCompute the cumulative histogram from the image histogram\nReplace each luminance value (L) in the original image using the formula: \\text{new luminance} = \\frac{255 \\times \\text{ cumulative histogram[L]}}{\\text{ total number of pixels }} \n\nAs a reminder, your task in this part of the assignment will be considerably easier if you decompose the problem into several helper functions and test each function independently as you go. The algorithm for performing histogram equalization is sufficiently complex that it would make sense to code it as a separate module by itself and import the necessary functions into ImageShop.py.",
    "crumbs": [
      "Milestone 4: The Equalize button"
    ]
  },
  {
    "objectID": "milestones/milestone2.html",
    "href": "milestones/milestone2.html",
    "title": "Milestone 2: The Grayscale button",
    "section": "",
    "text": "In this simplest of all the milestones, your job is to add a Grayscale button that replaces the image with a new one in which the image has been converted to grayscale. The code necessary for this transformation appears not only in the book but also in the file GrayscaleImage.py in the repository. To implement this milestone, you should not copy and paste the code from GrayscaleImage.py, but instead import the function or functions you need. The advantage of doing so is that there is then only one copy of the code, which is shared between the two applications. Copying code inevitably creates problems for software maintenance, since changes made to one copy may not be incorporated into the other, leading to incompatible versions.",
    "crumbs": [
      "Milestone 2: The Grayscale button"
    ]
  },
  {
    "objectID": "milestones.html",
    "href": "milestones.html",
    "title": "Introducing Milestones",
    "section": "",
    "text": "As per usual, this project has been divided up into a series of smaller tasks to help you approach the project in a controlled and testable fashion. For this project, each of the following milestones will focus on adding new buttons to the left of the screen and then implementing the desired image manipulation in a new function.",
    "crumbs": [
      "Introducing Milestones"
    ]
  },
  {
    "objectID": "extensions.html",
    "href": "extensions.html",
    "title": "Potential Extensions",
    "section": "",
    "text": "This project offers essentially unlimited possibilities for extensions. All you need to do is implement features from your favorite image editor! Here are a few ideas though:\n\nImplement a “posterize” button. Shepard Fairey’s iconic design of the campaign poster for President Obama’s 2008 campaign was widely adapted for other drawings. In this image, all pixels are converted to the closest equivalent color chosen from a restricted list of colors. The image below, for example, contains only red, an off-white ivory tone, and three shades of blue. Your extension could, for example, replace all intermediate colors with the closest match in Java’s predefined color palette or use some other strategy you find by searching around the web or thinking up on your own!\n\n\n\nExample of posterized image using around 5-6 colors.\n\n\nImplement an averaging filter. When using low-resolution cameras, images can look rather blotchy. The rightmost image below, for example, shows an image of Saturn taken by the Cassini probe. You can create an image like the one on the right, which looks much smoother, by replacing each pixel with a weighted average of its own luminance and that of its nearest neighbors. You could add a button to your ImageShop program that performs this sort of average.\n\n\n\nExample of an original grainy image on the left and smoothed output on the right.\n\n\nAdd a touch-up tool. If you need to edit an image, it is particularly useful to have a pencil-like tool that allows you to drop a new color on any pixel in the image. The usual strategy is to allow the user to pick a color first and then change individual pixels to that color by clicking on them with the mouse.\nImplement a crop box. In the basic assignment, the mouse is used only for buttons, but you could also use it to draw a rectangle on the screen and then limit the functions of the other operators to the region inside the rectangle. It could also make sense to add a Crop button that eliminates all pixels outside the crop box.\nWhatever else you want! Go wild! Lots of room for some potential ++ scores on this assignment.",
    "crumbs": [
      "Extensions",
      "Potential Extensions"
    ]
  },
  {
    "objectID": "milestones/milestone0.html",
    "href": "milestones/milestone0.html",
    "title": "Milestone 0: The Flip Horizontal button",
    "section": "",
    "text": "To start you off with a relatively straightforward task, add a new Flip Horizontal button that flips the image from left to right. To display the button on the screen, you simple need to copy the code that displays the Flip Vertical button, adding new functions flip_horizontal_action, which will be your button callback, and flip_horizontal, which actually implements the image transformation. The only function that requires any real change from the flip_vertical model is flip_horizontal, where you have to reverse each individual row in the pixel array instead of reversing the array as a whole. I suggest first adding the button (and making sure it appears on the screen), then the callback function and finally the transformation function itself to make sure you are understanding what each is doing along the way.",
    "crumbs": [
      "Milestone 0: The Flip Horizontal button"
    ]
  },
  {
    "objectID": "milestones/milestone1.html",
    "href": "milestones/milestone1.html",
    "title": "Milestone 1: Rotate Left and Right buttons",
    "section": "",
    "text": "Your next step is to add two buttons that rotate the image on the screen by 90°. Once again, the most challenging part of this milestone is adding the functions that actually transform the GImage. Implementing these rotations is a bit tricky, since you have to figure out where each of the old pixels ends up in the new image array. Since the dimensions of the new image are inverted from the original (the new width is the old height and vice versa), you need to create a new array with the correct number of elements in each dimension. Once you have done so, you need to copy each old pixel into the correct position in the new array. This process is illustrated in Figure 1, which shows where each pixel in the first row of the old array (before) moves to the new array (after) during a 90° rotation left (or counter-clockwise).\n\n\n\n\n\n\n\n\nFigure 1: Graphical depiction of rotating an image array 90° counter-clockwise (left). Note that what was previously the last column is now the first row, and what was the first row is now the first column.",
    "crumbs": [
      "Milestone 1: Rotate Left and Right buttons"
    ]
  },
  {
    "objectID": "introduction/existing_code.html",
    "href": "introduction/existing_code.html",
    "title": "Understanding the Existing Code",
    "section": "",
    "text": "There is already a decent amount of code included in the ImageShop project, across a few different files, so it is time well spent to ensure you understand what you are starting with.",
    "crumbs": [
      "Understanding the Existing Code"
    ]
  },
  {
    "objectID": "introduction/existing_code.html#button.py",
    "href": "introduction/existing_code.html#button.py",
    "title": "Understanding the Existing Code",
    "section": "button.py",
    "text": "button.py\nThe code for ImageShop.py in the repository uses a new class called GButton, defined in the button.py library, which is responsible for displaying the buttons on the screen. The GButton object type is really just a convenience: wrapping together a GRect, a GLabel and a mouse event listener all together for ease of use and placement. Creating a new GButton takes the text to display in the button, along with a function to call when the user clicks the button.\nIn general, you should not need to interact directly with this library. It has already been imported for you in ImageShop.py, and in the ImageShop code, the call to create a new GButton object appears within the function add_button, which also takes care of placing each new button just underneath the previous one in the button area.",
    "crumbs": [
      "Understanding the Existing Code"
    ]
  },
  {
    "objectID": "introduction/existing_code.html#grayscaleimage.py",
    "href": "introduction/existing_code.html#grayscaleimage.py",
    "title": "Understanding the Existing Code",
    "section": "GrayscaleImage.py",
    "text": "GrayscaleImage.py\nThis program is introduced in the PDF reader on pg 287 (pdf page 293), and contains three function definitions to help with displaying a grayscale version of a particular image. Two of these functions will likely be useful to you in this project, but one will not. Take some time to review what each function is accomplishing, so that you understand which you will want to use later. Keep in mind that instead of copying these functions over to ImageShop.py, you should instead import them. Again, you shouldn’t need to edit any code in this file, you’ll just import what you need and use it inside ImageShop.py.",
    "crumbs": [
      "Understanding the Existing Code"
    ]
  },
  {
    "objectID": "introduction/existing_code.html#imageshop.py",
    "href": "introduction/existing_code.html#imageshop.py",
    "title": "Understanding the Existing Code",
    "section": "ImageShop.py",
    "text": "ImageShop.py\nThis is the main file that you will be editing through most of the milestones. It starts with code already present to draw the starting screen and add the first few buttons. This code and its major functionality is highlighted below, where you can click on the circled numbers to the right to bring up descriptions of each code block.\n######################################################################\n# Name:\n# Collaborators (if any):\n# Section leader's name:\n# List of extensions made (if any):\n######################################################################\n\n\"\"\"\nThis program is the starter file for the ImageShop application, which\nimplements the \"Load\" and \"Flip Vertical\" buttons.\n\"\"\"\n\n0from filechooser import choose_input_file\nfrom pgl import GWindow, GImage, GRect\nfrom button import GButton\n\n# Constants\n\nGWINDOW_WIDTH = 900\nGWINDOW_HEIGHT = 500\nBUTTON_WIDTH = 125\nBUTTON_HEIGHT = 20\nBUTTON_MARGIN = 10\nBUTTON_BACKGROUND = \"#CCCCCC\"\n\n# Derived constants\n\nBUTTON_AREA_WIDTH = 2 * BUTTON_MARGIN + BUTTON_WIDTH\nIMAGE_AREA_WIDTH = GWINDOW_WIDTH - BUTTON_AREA_WIDTH\n\n# The image_shop application\n\ndef image_shop():\n1    def add_button(label, action):\n        \"\"\"\n        Adds a button to the region on the left side of the window\n        label is the text that will be displayed on the button and\n        action is the callback function that will be run when the\n        button is clicked.\n        \"\"\"\n        x = BUTTON_MARGIN\n        y = gw.next_button_y\n        button = GButton(label, action)\n        button.set_size(BUTTON_WIDTH, BUTTON_HEIGHT)\n        gw.add(button, x, y)\n        gw.next_button_y += BUTTON_HEIGHT + BUTTON_MARGIN\n\n2    def set_image(image):\n        \"\"\"\n        Sets image as the current image after removing the old one.\n        \"\"\"\n        if gw.current_image is not None:\n            gw.remove(gw.current_image)\n        gw.current_image = image\n        x = BUTTON_AREA_WIDTH + (IMAGE_AREA_WIDTH - image.get_width()) / 2\n        y = (gw.get_height() - image.get_height()) / 2\n        gw.add(image, x, y)\n\n3    def load_button_action():\n        \"\"\"Callback function for the Load button\"\"\"\n        filename = choose_input_file()\n        if filename != \"\":\n            set_image(GImage(filename))\n\n4    def flip_vertical_action():\n        \"\"\"Callback function for the Flip Vertical button\"\"\"\n        if gw.current_image is not None:\n            set_image(flip_vertical(gw.current_image))\n        \n5    gw = GWindow(GWINDOW_WIDTH, GWINDOW_HEIGHT)\n    button_area = GRect(0, 0, BUTTON_AREA_WIDTH, GWINDOW_HEIGHT)    \n    button_area.set_filled(True)\n    button_area.set_color(BUTTON_BACKGROUND)\n    gw.add(button_area)\n    gw.next_button_y = BUTTON_MARGIN\n    gw.current_image = None\n    add_button(\"Load\", load_button_action)\n    add_button(\"Flip Vertical\", flip_vertical_action)\n\n# Creates a new GImage from the original one by flipping it vertically.\n\n6def flip_vertical(image):\n    array = image.get_pixel_array()\n    return GImage(array[::-1])\n\n# Startup code\n\nif __name__ == \"__main__\":\n    image_shop()\n\n0\n\nThe initial imports of necessary functions. You will need to add to this later!\n\n1\n\nThe provided function to add a new button to the window. You need to provide both the text that should be displayed on the button and callback function to be run when the button is pressed. Note that the placement of the button is automatically determined. You should call this function whenever you want to create a new button.\n\n2\n\nThe provided function to display a GImage to the screen. It takes care of clearing out the old value of gw.current_image, setting it to the new image, and then adding the image centered in the right portion of the window. You should call this function whenever you want to update what is displayed on the right side of the ImageShop window.\n\n3\n\nThe callback function responsible for prompting you for an image when the Load button is pressed. You should not need to edit this function, but you may want to draw inspiration from it when you need to implement a similar prompt as part of Milestone 3.\n\n4\n\nThe callback function which is run when the Flip Vertical button is pressed. Note how it accesses the current value of gw.current_image and passes it into the flip_vertical function, then takes the output of flip_vertical and sets the image on the screen to whatever image flip_vertical returned. This will be a very common pattern for many of the buttons you’ll create.\n\n5\n\nInitializes the major window components, a few variables, and then starts adding buttons. For the most part, you’ll just need to add your code to add your own buttons below this.\n\n6\n\nThe image manipulation function for flipping the image vertically. Note that it take in a GImage as an argument, and then returns a new GImage at the end. Again, this will be a pattern most of your image manipulation functions should follow.",
    "crumbs": [
      "Understanding the Existing Code"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project 2: Breakout",
    "section": "",
    "text": "Most of you have probably had the occasion to use some sort of image editing software such as Adobe Photoshop™ or Adobe Illustrator™. In this assignment, you will have the chance to build a simple version of an image editor which we will call ImageShop, which implements several simple operations on images along with a few more interesting ones.\nPerforming image manipulation in Python requires the use of the Pillow library, which is not included in the normal Python distribution. This should have already been resolved on everyone’s systems from using Karel, but if you are having issues, please contact me and I can help get you sorted out.\nAs per usual, you will submit this project through GitHub Classroom, and you can find the link to accept the project and download the initial template files below.\nAccept Project\n\n\nStrategies and Hints\nThere are no new strategies for approaching this project, just the same ideas as before:\n\nStart as soon as possible! This assignment is due in just over a week, which will be here before you know it. If you wait until the day before this project is due, you will have a very hard time getting it all together.\nImplement the program in stages, as described in this handout. This project can be a bit more forgiving in this aspect than others, but please don’t try to get everything working all at once. Implement the various pieces of the project one at a time and test them to make sure that each one is working before you move on to the next phase.\nDon’t try to extend the program until you get the basic functionality working! The ImageShop project is perhaps the easiest project to come up with extensions for, as you can just ask yourself what cool operations you want to perform on an image. But make sure that you have all the required milestones working and well tested before starting to add extensions."
  }
]